{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171a2f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325c12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank  of t:  1\n",
      "Shape of t:  (7,)\n"
     ]
    }
   ],
   "source": [
    "print('Rank  of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81fd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1]  =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:]     =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "print('t[0] t[1] t[-1] = ', t[0], t[1], t[-1]) # Element t[0] t[1] t[-1] = 0.0 1.0 6.0\n",
    "print('t[2:5] t[4:-1]  = ', t[2:5], t[4:-1]) # Slicing t[2:5] t[4:-1] = [2. 3. 4.] [4. 5.]\n",
    "print('t[:2] t[3:]     = ', t[:2], t[3:]) # Slicing t[:2] t[3:] = [0. 1.] [3. 4. 5. 6.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c021eac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# 2D array\n",
    "\n",
    "t = torch.FloatTensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4dd394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) # Rank\n",
    "print(t.size()) # Shape\n",
    "print(t[:, 1])\n",
    "print(t[:, 1].size())\n",
    "print(t[:, :-1])\n",
    "\n",
    "# Slicing 은 끝번호에 해당하는 것은 포함 하지 않음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0bb5f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasring : 서로 크기가 다른 행렬들이 사칙 연산을 수행할 수 있도록 자동으로 크기를 맞춰서 연산을 수행\n",
    "# Same Shape\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da56a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # 3 -> [[3, 3]]\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fb5ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b074aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Mul vs Matmul\n",
      "-------------\n",
      "Shape of Matrix 1 :  torch.Size([2, 2])\n",
      "Shape of Matrix 2 :  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Multiplication & Matrix Multiplication\n",
    "# : Element-wise 곱셈에선 서로 다른 크기의 행렬이 브로드캐스팅 된 후에 곱셈이 수행\n",
    "# : 동일한 크기의 행렬이 동일한 위치에 있는 원소끼리 곱하는 것과 같은 결과를 얻게 됨.\n",
    "print()\n",
    "print('-------------')\n",
    "print('Mul vs Matmul')\n",
    "print('-------------')\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1 : ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2 : ', m2.shape) # 2 x 1\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb2cb323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "# : .mean()에서 dim을 인자로 주게 되면 어느 차원을 기준으로 평균을 구할지 설정가능\n",
    "# : 아무 것도 설정하지 않으면 전체 평균을 계산\n",
    "# : dim = 0은 첫번째 차원 즉 행을 기준으로 평균을 계산.\n",
    "# : dim = 0이라는 것은 첫번째 차원을 의미. 행렬에서 첫번째 차원은 '행'을 의미\n",
    "# : 그리고 인자로 dim을 준다면 해당 차원을 제거한다는 의미 -> '열'만 남기겠다는 의미\n",
    "# : dim = 1은 두번째 차원 즉 열을 기준으로 평균을 계산\n",
    "# : dim = -1은 마지막 차원으로 평균을 계산하는데 위의 예제에선 마지막 차원 = 열\n",
    "# : t2.mean(dim=1)과 출력값이 동일\n",
    "\n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "714b0fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can only calculate the mean of floating types. Got Long instead.\n"
     ]
    }
   ],
   "source": [
    "# Can't Use mean() on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8e476c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5cc33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean())\n",
    "print(t.mean(dim=0)) # ↓ : 행을 기준으로\n",
    "print(t.mean(dim=1)) # → : 열을 기준으로\n",
    "print(t.mean(dim=-1)) # 마지막 차원으로 평균을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec74e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Sum : 덧셈은 편균과 사용방법이 완전히 동일\n",
    "t = torch.FloatTensor([[1, 2] , [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e074f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())\n",
    "print(t.sum(dim=0)) # ↓ : 행을 기준으로\n",
    "print(t.sum(dim=1)) # → : 열을 기준으로\n",
    "print(t.sum(dim=-1)) # 마지막 차원으로 평균을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e750a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Max & Argmax\n",
    "# : Max는 최대값을 반환하고 Argmax는 최대값을 가진 인덱스를 반환\n",
    "# : 차원을 지정하면 두개의 데이터를 뽑을 수 있음\n",
    "# : t.max(dim=0)[0] 이 최대값 (max)를 나타내고,\n",
    "# : t.max(dim=0)[1]이 최대값을 갖는 데이터 인덱스를 나타냄.\n",
    "t = torch.FloatTensor([[1, 2] , [3, 4]])\n",
    "# [ 1   3 ]   index 값\n",
    "# [ 2   4 ]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "518ebc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max     :  tensor([3., 4.])\n",
      "Argmax  :  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(t.max()) # Retunrs one Value : max\n",
    "print(t.max(dim=0)) # Returns two Values : max and argmax\n",
    "print('Max     : ', t.max(dim=0)[0])\n",
    "print('Argmax  : ', t.max(dim=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "993055a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=1))\n",
    "print(t.max(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe847a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# View : 원소의 수를 유지하면서 텐서의 크기 변경.\n",
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4 ,5]],\n",
    "              \n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1ff90fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 3]))  # -1 : pytorch가 알아서... 3 : 차원의 길이 3으로\n",
    "print(ft.view([-1, 3]).shape) \n",
    "# 현재 3차원 텐서를 2차원 텐서로 변경하되 (?,3)의 크기로 변경하라는 의미.\n",
    "# 내부적으로 크기 변환은 (2, 2, 3) -> (2 x 2, 3) -> (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53b8af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 1, 3])) # (? x 1 x 3)으로 변경\n",
    "print(ft.view([-1, 1, 3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
