{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-alexnet-cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQwP3TUNKe4J"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4jtUYrqLCLl"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 40\n",
        "\n",
        "# Architecture\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Other\n",
        "DEVICE = \"cuda:0\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s64aRVIROZ--",
        "outputId": "2c3b3112-f4ce-462c-fba6-94e94d952f66"
      },
      "source": [
        "train_indices = torch.arange(0, 48000)\n",
        "valid_indices = torch.arange(48000, 50000)\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
        "                                      transforms.RandomCrop((64, 64)),\n",
        "                                      transforms.ToTensor()])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
        "                                     transforms.CenterCrop((64, 64)),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "train_and_valid = datasets.CIFAR10(root='data', \n",
        "                                   train=True, \n",
        "                                   transform=train_transform,\n",
        "                                   download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=test_transform,\n",
        "                                download=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=True)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset, \n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=4,\n",
        "                          shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         num_workers=4,\n",
        "                         shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTS7yOP1Ou7H",
        "outputId": "83eebc02-cff0-428c-ffd7-b6a9a61060c2"
      },
      "source": [
        "# Checking the dataset\n",
        "print('Training Set:\\n')\n",
        "for images, labels in train_loader:\n",
        "  print('Image batch dimensions:', images.size())\n",
        "  print('Image label dimensions:', labels.size())\n",
        "  print(labels)\n",
        "  break\n",
        "\n",
        "# Checking the dataset\n",
        "print('\\nValidation Set:\\n')\n",
        "for images, labels in valid_loader:\n",
        "  print('Image batch dimensions:', images.size())\n",
        "  print('Image label dimensions:', labels.size())\n",
        "  print(labels)\n",
        "  break\n",
        "\n",
        "# Checking the dataset\n",
        "print('\\nTesting Set:\\n')\n",
        "for images, labels in test_loader:\n",
        "  print('Image batch dimensions:', images.size())\n",
        "  print('Image label dimensions:', labels.size())\n",
        "  print(labels)\n",
        "  break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([9, 6, 7, 5, 0, 1, 1, 2, 9, 8, 1, 0, 1, 8, 0, 3, 8, 3, 2, 0, 6, 3, 8, 7,\n",
            "        7, 1, 1, 7, 2, 4, 4, 8, 5, 3, 3, 9, 5, 8, 8, 9, 8, 7, 5, 4, 1, 0, 8, 5,\n",
            "        8, 4, 0, 9, 7, 8, 1, 8, 9, 1, 8, 0, 3, 6, 5, 6, 1, 7, 4, 5, 7, 1, 7, 8,\n",
            "        1, 8, 2, 5, 6, 5, 3, 5, 9, 3, 8, 9, 3, 3, 0, 8, 5, 9, 7, 0, 0, 5, 0, 7,\n",
            "        8, 0, 4, 2, 7, 4, 2, 6, 1, 9, 7, 7, 4, 4, 0, 6, 8, 7, 6, 1, 2, 0, 8, 8,\n",
            "        1, 5, 6, 3, 3, 4, 6, 4, 8, 0, 2, 5, 6, 3, 7, 7, 1, 1, 5, 2, 9, 4, 6, 4,\n",
            "        3, 8, 6, 5, 3, 2, 8, 4, 1, 3, 4, 7, 0, 5, 3, 7, 4, 0, 5, 0, 5, 5, 5, 2,\n",
            "        1, 7, 4, 6, 9, 0, 0, 5, 5, 6, 6, 5, 4, 4, 7, 5, 4, 6, 4, 1, 3, 6, 9, 7,\n",
            "        9, 5, 7, 4, 5, 7, 0, 3, 5, 1, 1, 6, 6, 8, 4, 6, 8, 2, 8, 8, 5, 2, 2, 1,\n",
            "        7, 6, 0, 9, 4, 7, 2, 6, 4, 7, 7, 5, 6, 6, 2, 8, 0, 2, 0, 1, 2, 3, 3, 4,\n",
            "        7, 9, 6, 9, 9, 2, 6, 8, 7, 7, 8, 2, 7, 8, 4, 7])\n",
            "\n",
            "Validation Set:\n",
            "\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([1, 0, 2, 1, 5, 3, 5, 3, 4, 0, 5, 5, 2, 0, 2, 2, 4, 9, 4, 3, 7, 1, 6, 4,\n",
            "        0, 2, 0, 6, 3, 7, 1, 9, 0, 9, 9, 7, 1, 3, 4, 3, 3, 7, 8, 6, 8, 3, 4, 6,\n",
            "        5, 6, 5, 9, 3, 1, 0, 7, 5, 6, 3, 0, 7, 9, 3, 3, 2, 6, 7, 6, 4, 0, 6, 0,\n",
            "        6, 2, 2, 1, 8, 5, 1, 6, 4, 8, 2, 5, 9, 3, 1, 4, 3, 2, 2, 4, 2, 2, 0, 2,\n",
            "        0, 3, 9, 7, 0, 2, 2, 6, 7, 0, 9, 8, 0, 0, 5, 7, 3, 1, 5, 1, 9, 2, 3, 0,\n",
            "        8, 9, 1, 9, 8, 8, 9, 8, 1, 9, 0, 3, 3, 8, 3, 5, 0, 2, 1, 5, 9, 1, 6, 4,\n",
            "        3, 0, 2, 0, 0, 7, 9, 9, 9, 7, 6, 5, 8, 3, 8, 4, 6, 5, 3, 4, 8, 9, 7, 6,\n",
            "        8, 2, 3, 9, 4, 1, 0, 8, 6, 7, 9, 4, 7, 5, 1, 3, 6, 1, 3, 0, 6, 5, 6, 4,\n",
            "        9, 5, 2, 4, 9, 0, 7, 5, 3, 6, 4, 6, 7, 2, 6, 5, 5, 0, 9, 4, 0, 8, 6, 1,\n",
            "        4, 0, 6, 7, 5, 4, 2, 4, 1, 8, 9, 8, 4, 6, 6, 9, 2, 3, 1, 4, 7, 7, 9, 0,\n",
            "        5, 6, 2, 3, 2, 5, 0, 8, 3, 8, 2, 2, 0, 8, 0, 7])\n",
            "\n",
            "Testing Set:\n",
            "\n",
            "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
            "Image label dimensions: torch.Size([256])\n",
            "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
            "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
            "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
            "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
            "        6, 0, 0, 7, 4, 5, 6, 3, 1, 1, 3, 6, 8, 7, 4, 0, 6, 2, 1, 3, 0, 4, 2, 7,\n",
            "        8, 3, 1, 2, 8, 0, 8, 3, 5, 2, 4, 1, 8, 9, 1, 2, 9, 7, 2, 9, 6, 5, 6, 3,\n",
            "        8, 7, 6, 2, 5, 2, 8, 9, 6, 0, 0, 5, 2, 9, 5, 4, 2, 1, 6, 6, 8, 4, 8, 4,\n",
            "        5, 0, 9, 9, 9, 8, 9, 9, 3, 7, 5, 0, 0, 5, 2, 2, 3, 8, 6, 3, 4, 0, 5, 8,\n",
            "        0, 1, 7, 2, 8, 8, 7, 8, 5, 1, 8, 7, 1, 3, 0, 5, 7, 9, 7, 4, 5, 9, 8, 0,\n",
            "        7, 9, 8, 2, 7, 6, 9, 4, 3, 9, 6, 4, 7, 6, 5, 1, 5, 8, 8, 0, 4, 0, 5, 5,\n",
            "        1, 1, 8, 9, 0, 3, 1, 9, 2, 2, 5, 3, 9, 9, 4, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iK5saYtRfNW"
      },
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "        #features : 특징을 추출하는 layers : 총 5번의 컨볼루션 연산을 거친다\n",
        "        self.features = nn.Sequential(\n",
        "            #1. 3 -> 64채널로 컨볼루션 연산 + MaxPolling\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            #2. 64 -> 192채널로 컨볼루션 연산 + MaxPolling\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            #3. 192 -> 384채널로 컨볼루션 연산\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #4. 384 -> 256채널로 컨볼루션 연산\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #5. 256 -> 256채널로 컨볼루션 연산 + MaxPolling\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        #avgpool : 풀링 기법 중 하나, avgpooling을 하면 텐서 모양을 classifier에 맞춰준다.\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        #classifier : 추출된 특징을 기반으로 데이터를 분류하는 layers\n",
        "        self.classifier = nn.Sequential\n",
        "        (\n",
        "            nn.Dropout(0.5),\n",
        "            #1. 256x6x6 의 특징을, 4096개로 압축한다.\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            #2. 4096개의 특징 차원은 유지하되 한번더 정제한다.\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #4. 차원을 클래수 개수만큼으로 축소시키면서 클래스 분류를 완료한다. \n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        #forward : 순전파함수\n",
        "    def forward(self, x):\n",
        "        #1. 먼저 features(x)를 통해, x의 특징을 추출한다.\n",
        "        x = self.features(x)\n",
        "        #2. 평균화작업을 하면서, 데이터의 모양을 맞춘다.\n",
        "        x = self.avgpool(x)\n",
        "        #3. classifer를 통해 클래스를 분류하고 softmax로 가장 확률이 높은 클래스를 선택하게 한다.\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        logits = self.classifier(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OKOdEVPUXOe"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "model = AlexNet(NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_znrItyUpzu"
      },
      "source": [
        "def compute_acc(model, data_loader, device):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    #eval() : 모델을 평가모드로 전환\n",
        "    model.eval()\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "        #features : 데이터가 담겨있는 텐서\n",
        "        features = features.to(device)\n",
        "        #targets : 정답이 담겨있는 텐서 \n",
        "        targets = targets.to(device)\n",
        "        #probas : 모델이 예측한 각 클래스에 속할 확률을 담고 있음\n",
        "        logits, probas = model(features)\n",
        "        #predicted_labels : 모델이 예측한 정답\n",
        "        _, predicted_labels = torch.max(probas, 1)\n",
        "        num_examples += targets.size(0)\n",
        "        assert predicted_labels.size() == targets.size()\n",
        "        #맞은 경우를 세서 확률로 만들어 줌\n",
        "        correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100\n",
        "    \n",
        "#time.time() 현재 시간을 기록함\n",
        "start_time = time.time()\n",
        "\n",
        "cost_list = []\n",
        "train_acc_list, valid_acc_list = [], []\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    #모델을 학습모드로 바꾼다.\n",
        "    model.train()\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "        \n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "            \n",
        "        #모델을 통해 예측을 수행하고\n",
        "        logits, probas = model(features)\n",
        "        #loss인 cross_entropy를 구한다.\n",
        "        cost = F.cross_entropy(logits, targets)\n",
        "        #backpropagation 전에는 optimizer의 남아있는 기울기를 제거\n",
        "        optimizer.zero_grad()\n",
        "        #backpropagation 수행\n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        #################################################\n",
        "        ### CODE ONLY FOR LOGGING BEYOND THIS POINT\n",
        "        ################################################\n",
        "        cost_list.append(cost.item())\n",
        "        if not batch_idx % 150:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
        "                   f' Cost: {cost:.4f}')\n",
        "\n",
        "        \n",
        "    #모델을 평가모드로 바꾸기\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False): # save memory during inference\n",
        "        train_acc = compute_acc(model, train_loader, device=DEVICE)\n",
        "        valid_acc = compute_acc(model, valid_loader, device=DEVICE)\n",
        "        #validation 데이터셋에서 평가를 수행해본다.\n",
        "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n'\n",
        "              f'Train ACC: {train_acc:.2f} | Validation ACC: {valid_acc:.2f}')\n",
        "        \n",
        "        train_acc_list.append(train_acc)\n",
        "        valid_acc_list.append(valid_acc)\n",
        "    \n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Time elapsed: {elapsed:.2f} min')\n",
        "  \n",
        "elapsed = (time.time() - start_time)/60\n",
        "print(f'Total Training Time: {elapsed:.2f} min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zlx72U_WfYe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8EksQMacqao"
      },
      "source": [
        "#plt.plot()을 통해 시각화한다\n",
        "plt.plot(cost_list, label='Minibatch cost')\n",
        "plt.plot(np.convolve(cost_list, \n",
        "                     np.ones(200,)/200, mode='valid'), \n",
        "         label='Running average')\n",
        "\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.xlabel('Iteration')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56qYyXIycsgv"
      },
      "source": [
        "plt.plot(np.arange(1, NUM_EPOCHS+1), train_acc_list, label='Training')\n",
        "plt.plot(np.arange(1, NUM_EPOCHS+1), valid_acc_list, label='Validation')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wTsn1FlcxFH"
      },
      "source": [
        "with torch.set_grad_enabled(False):\n",
        "    test_acc = compute_acc(model=model,\n",
        "                           data_loader=test_loader,\n",
        "                           device=DEVICE)\n",
        "    \n",
        "    valid_acc = compute_acc(model=model,\n",
        "                            data_loader=valid_loader,\n",
        "                            device=DEVICE)\n",
        "    \n",
        "\n",
        "print(f'Validation ACC: {valid_acc:.2f}%')\n",
        "print(f'Test ACC: {test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}